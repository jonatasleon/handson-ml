{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zlib import crc32\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join('datasets', 'housing')\n",
    "HOUSING_URL = DOWNLOAD_ROOT + 'datasets/housing/housing.tgz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, 'housing.tgz')\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    with tarfile.open(tgz_path) as housing_tgz:\n",
    "        housing_tgz.extractall(path=housing_path)\n",
    "\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, 'housing.csv')\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "class CombinedAttributeAdder(BaseEstimator, TransformerMixin):\n",
    "    rooms_ix = 3\n",
    "    bedrooms_ix = 4\n",
    "    population_ix = 5\n",
    "    household_ix = 6\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        attrs = []\n",
    "        rooms_per_household = X[:, self.rooms_ix] / X[:, self.household_ix]\n",
    "        attrs.append(rooms_per_household)\n",
    "        \n",
    "        population_per_household = X[:, self.population_ix] / X[:, self.household_ix]\n",
    "        attrs.append(population_per_household)\n",
    "        \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, self.bedrooms_ix] / X[:, self.rooms_ix]\n",
    "            attrs.append(bedrooms_per_room)\n",
    "        \n",
    "        \n",
    "        return np.c_[X, np.stack(attrs, axis=1)]\n",
    "        \n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "\n",
    "def describe_model(model_reg):\n",
    "    some_data = housing.iloc[:5]\n",
    "    some_labels = housing_labels.iloc[:5]\n",
    "    some_data_prepared = full_pipeline.transform(some_data)\n",
    "    \n",
    "    housing_predictions = model_reg.predict(housing_prepared)\n",
    "    model_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "    model_rmse = np.sqrt(model_mse)\n",
    "    \n",
    "    scores = cross_val_score(model_reg, housing_prepared, housing_labels,\n",
    "                             scoring='neg_mean_squared_error', cv=10)\n",
    "    scores = np.sqrt(-scores)\n",
    "    \n",
    "    print(\"Predictions:\", model_reg.predict(some_data_prepared))\n",
    "    print(\"Labels:\", list(some_labels))\n",
    "    print(\"RMSE:\", model_rmse)\n",
    "    print('\\nScores:', scores)\n",
    "    print('Mean:', scores.mean())\n",
    "    print('Std Deviation:', scores.std())\n",
    "\n",
    "    \n",
    "def describe_search_cv(search_cv, model_reg, params):\n",
    "    cvres = search_cv.cv_results_\n",
    "    for neg_mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "        print(np.sqrt(-neg_mean_score), params)\n",
    "    describe_model(search_cv.best_estimator_)\n",
    "    print('Best Params:', search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop('income_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_columns = ['ocean_proximity']\n",
    "num_columns = list(housing.drop(obj_columns, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_columns)),\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('attribs_adder', CombinedAttributeAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(obj_columns)),\n",
    "    ('encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [210644.60459286 317768.80697211 210956.43331178  59218.98886849\n",
      " 189747.55849879]\n",
      "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n",
      "RMSE: 68628.19819848922\n",
      "\n",
      "Scores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
      " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
      " 71552.91566558 67665.10082067]\n",
      "Mean: 69052.46136345083\n",
      "Std Deviation: 2731.674001798343\n"
     ]
    }
   ],
   "source": [
    "describe_model(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [286600. 340600. 196900.  46300. 254500.]\n",
      "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n",
      "RMSE: 0.0\n",
      "\n",
      "Scores: [68838.58407569 66419.91932739 72324.92192765 70149.70897452\n",
      " 71242.83444674 74100.33743129 71814.12226571 70148.00601031\n",
      " 77005.49922101 70781.58452663]\n",
      "Mean: 71282.55182069573\n",
      "Std Deviation: 2729.512615559486\n"
     ]
    }
   ],
   "source": [
    "describe_model(tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(n_estimators=10)\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [274520. 313350. 214590.  47760. 204980.]\n",
      "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n",
      "RMSE: 22107.118315673048\n",
      "\n",
      "Scores: [52418.49572561 49050.22904725 52634.08748329 54721.37623165\n",
      " 52964.64215376 55255.03501993 52075.21749423 49750.19494697\n",
      " 55588.25673959 51501.92668299]\n",
      "Mean: 52595.94615252785\n",
      "Std Deviation: 2070.0110164385883\n"
     ]
    }
   ],
   "source": [
    "describe_model(forest_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para salvar um modelo a ser carregado depois\n",
    "```py\n",
    "joblib.dump(forest_reg, 'forest_reg.pkl')\n",
    "loaded_model = joblib.load('forest_reg.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [3, 10, 30],\n",
    "        'max_features': [2, 4, 6, 8],\n",
    "    },\n",
    "    {\n",
    "        'bootstrap': [False],\n",
    "        'n_estimators': [3, 10],\n",
    "        'max_features': [2, 3, 4],\n",
    "    },\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "describe_search_cv(grid_search, model_reg=forest_reg, params=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': [8, .2, .4, .75],\n",
    "    },\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "describe_search_cv(grid_search, model_reg=forest_reg, params=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_dist = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [8],\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"n_estimators\": [95]\n",
    "}\n",
    "forest_reg = RandomForestRegressor()\n",
    "random_search = RandomizedSearchCV(forest_reg, param_distributions=param_dist, n_iter=20, cv=5, scoring='neg_mean_squared_error')\n",
    "random_search.fit(housing_prepared, housing_labels)\n",
    "describe_search_cv(random_search, model_reg=forest_reg, params=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (geo)",
   "language": "python",
   "name": "python3-geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
